{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef90f1fa-5ccc-4394-b131-ff7134e41b20",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056530bd-1926-4e23-a2da-b318b92047e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa55371-614a-4f8c-a805-ae347d0a2c83",
   "metadata": {},
   "source": [
    "# Loading The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ca46ff-28f2-41c1-ac4c-043ca1eeebbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\abhis\\Downloads\\IMDB-Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7061c4eb-9518-483e-995b-52c0de81a2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e0a678-5d4e-4f47-9d4c-02e4dc4b06f2",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4633420-2cd7-4fa2-b3c0-41c4bdf32ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode sentiment (positive -> 1, negative -> 0)\n",
    "data.sentiment.replace({'positive': 1, 'negative': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ec87fe-164f-4bb3-9add-523bc96d0165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "5  Probably my all-time favorite movie, a story o...          1\n",
       "6  I sure would like to see a resurrection of a u...          1\n",
       "7  This show was an amazing, fresh & innovative i...          0\n",
       "8  Encouraged by the positive comments about this...          0\n",
       "9  If you like original gut wrenching laughter yo...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f4b3c-2c2a-4197-a93d-c80356d45886",
   "metadata": {},
   "source": [
    "## Removing HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1446f008-3d78-4045-8be7-4069b5e8f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    return re.sub(r'<.*?>', '', text)\n",
    "data['review'] = data['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac7701-cba9-4ae2-b06f-29e4faa84fc9",
   "metadata": {},
   "source": [
    "## Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e82992b-a41d-403d-b7a3-9e1df1180381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_chars(text):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "data['review'] = data['review'].apply(remove_special_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03607bd3-b0eb-4cbd-914e-637627e4b2cc",
   "metadata": {},
   "source": [
    "## Converting to Lower Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "300283a6-6055-4bd1-ad67-d8dc7ae018ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lowercase(text):\n",
    "    return text.lower()\n",
    "data['review'] = data['review'].apply(convert_to_lowercase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a43960-3a9a-4a65-97ea-8ee254f55b9d",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bb4d43b-2ae1-44a0-90b6-11efbc0fe758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "data['review'] = data['review'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaec978-22ea-4208-a825-b3573caaddb1",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f2d17cb-02c4-47d5-b79c-14f94d14929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(text):\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    words = word_tokenize(text)\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "data['review'] = data['review'].apply(apply_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac77fc6-8c2e-4bb9-86f9-66d81022d99a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review mention watch oz episod youll hook ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review mention watch oz episod youll hook ...          1\n",
       "1  wonder littl product film techniqu unassum old...          1\n",
       "2  thought wonder way spend time hot summer weeke...          1\n",
       "3  basic there famili littl boy jake think there ...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbe688-0ab0-4188-91ae-f9e1456a5e60",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1acbf1d2-7e36-48a7-b4bd-8a345f03b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer(num_words=10000)  # Limit to 10,000 most frequent words\n",
    "tokenizer.fit_on_texts(data['review'])\n",
    "sequences = tokenizer.texts_to_sequences(data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c6a5c5-44af-4c5e-b9cc-75abe593c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "X = pad_sequences(sequences, maxlen=200)  # Ensure all sequences are 200 words long\n",
    "y = data['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bdd4a-db28-404a-b66d-61c8dbc1c142",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "861b86bc-dc62-492b-9ecc-136a8c8e94cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: X=(40000, 200), y=(40000,)\n",
      "Test shapes: X=(10000, 200), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "trainx, testx, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Train shapes: X={trainx.shape}, y={trainy.shape}\")\n",
    "print(f\"Test shapes: X={testx.shape}, y={testy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3f8485-53b6-468a-8e54-002fa8ff4a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=128, input_length=200),  # Embedding layer\n",
    "    LSTM(128, return_sequences=True),  # First LSTM layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    LSTM(64),  # Second LSTM layer\n",
    "    Dropout(0.2),  # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "357fd53e-155e-4590-b5a6-5543c4e08d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 257ms/step - accuracy: 0.7852 - loss: 0.4363 - val_accuracy: 0.8809 - val_loss: 0.2835\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 261ms/step - accuracy: 0.9095 - loss: 0.2347 - val_accuracy: 0.8773 - val_loss: 0.3038\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 264ms/step - accuracy: 0.9355 - loss: 0.1710 - val_accuracy: 0.8814 - val_loss: 0.3095\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 270ms/step - accuracy: 0.9571 - loss: 0.1233 - val_accuracy: 0.8777 - val_loss: 0.3455\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 271ms/step - accuracy: 0.9733 - loss: 0.0799 - val_accuracy: 0.8707 - val_loss: 0.4201\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(trainx, trainy, epochs=5, batch_size=64, validation_data=(testx, testy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a920fa-330e-437c-ab75-7e5e5e85e874",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02dde0bf-09e2-4910-ae57-e76d89a0a161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 53ms/step - accuracy: 0.8735 - loss: 0.4102\n",
      "Test Accuracy: 0.8707\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 54ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.90      0.83      0.86      4961\n",
      "    Positive       0.85      0.91      0.88      5039\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(testx, testy)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "y_pred = (model.predict(testx) > 0.5).astype(\"int32\")\n",
    "print(classification_report(testy, y_pred, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ff910-1706-4309-9996-aa27e64b05a6",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "900755a8-c9e2-4523-96f4-26161e8d118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "model.save('lstm_sentiment_model.h5')\n",
    "\n",
    "# Save the tokenizer\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb4ff9-b94b-4eb5-b220-9cc329e608fd",
   "metadata": {},
   "source": [
    "# Testing on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65c0183a-d249-4e6c-a03c-9374921f2577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step\n",
      "Sentiment: Negative\n"
     ]
    }
   ],
   "source": [
    "# Load saved model and tokenizer\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('lstm_sentiment_model.h5')\n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "# Preprocess and predict sentiment for a new review\n",
    "def preprocess_review(review):\n",
    "    review = remove_html_tags(review)\n",
    "    review = remove_special_chars(review)\n",
    "    review = convert_to_lowercase(review)\n",
    "    review = remove_stopwords(review)\n",
    "    review = apply_stemming(review)\n",
    "    return review\n",
    "\n",
    "new_review = \"\"\"Terrible. Complete trash. Brainless tripe. Insulting to anyone who isn't an 8 year old fan boy.\"\"\"\n",
    "cleaned_review = preprocess_review(new_review)\n",
    "sequence = tokenizer.texts_to_sequences([cleaned_review])\n",
    "padded_sequence = pad_sequences(sequence, maxlen=200)\n",
    "\n",
    "# Prediction\n",
    "prediction = model.predict(padded_sequence)\n",
    "print(\"Sentiment:\", \"Positive\" if prediction > 0.5 else \"Negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
